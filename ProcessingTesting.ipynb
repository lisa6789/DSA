{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tika import parser\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document tokenization after text pre-preprocessing to differentiate types then token based on type\n",
    "\n",
    "input_path = 'C:\\\\test'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# have df be document, sentences, words, pos\n",
    "# do keyword searching from list\n",
    "# contextualise search using pos\n",
    "d = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Tika to parse the file\n",
    "def parsewithtika(inputfile):\n",
    "    parsed = parser.from_file(inputfile)\n",
    "    # Extract the text content from the parsed file\n",
    "    psd = parsed[\"content\"]\n",
    "    return re.sub(r'\\s+', ' ', psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenmakerwords(inputfile):\n",
    "    # Create tokens\n",
    "    tokens = word_tokenize(inputfile)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    import string\n",
    "    stripped = [w.strip(string.punctuation) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    text = nltk.Text(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language filter\n",
    "def filterlanguage(inputfile):\n",
    "    if detect(inputfile) != 'en':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokens, parts of speech tagging\n",
    "def wordtokens(dataframe):\n",
    "    dataframe['words'] = (dataframe['sentences'].apply(lambda x: [word_tokenize(item) for item in x]))\n",
    "    dataframe['pos'] = dataframe['words'].apply(lambda x: [nltk.pos_tag(item) for item in x])\n",
    "    dataframe['allwords'] = d['words'].apply(lambda x: [item.strip(string.punctuation).lower() for sublist in x for item in sublist])\n",
    "    dataframe['allwords'] = (dataframe['allwords'].apply(lambda x: [item for item in x if item.isalpha()\n",
    "                                                               and item not in stop_words]))\n",
    "    dataframe['mfreq'] = d['allwords'].apply(nltk.FreqDist)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031918comments2.authcheckdam.pdf\n",
      "881961_CHECKLIST-2014_rev62714.pdf\n",
      "DomesticWireFunds.pdf\n",
      "Order Confirmation.pdf\n",
      "Orderconf.pdf\n",
      "Patient+Type+2+opt-out+letter+v1.0.pdf\n",
      "r003.pdf\n",
      "Sample Grade and Receipt Documents.pdf\n",
      "START_AM2014_QuickFireTwo.pdf\n",
      "START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014.pdf\n",
      "START_ISIL_Lesson1_ObjectivesScenariosforISIL.pdf\n",
      "START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014.pdf\n",
      "water-companies-letter-SoS-to-Ofwat-180131.pdf\n"
     ]
    }
   ],
   "source": [
    "# Main loop function\n",
    "# Iterate over all files in the folder and process each one in turn\n",
    "for input_file in glob.glob(os.path.join(input_path, '*.*')):\n",
    "    # Grab the file name\n",
    "    filename = os.path.basename(input_file)\n",
    "    fname = os.path.splitext(filename)[0]\n",
    "    print(filename)\n",
    "\n",
    "    # Parse the file to get to the text\n",
    "    parsed = parsewithtika(input_file)\n",
    "\n",
    "    # Language detection algorithm is non - deterministic, which means that if you try to run it on a text which is\n",
    "    # either too short or too ambiguous, you might get different results every time you run it\n",
    "    if filterlanguage(parsed):\n",
    "        continue\n",
    "\n",
    "    tokenised = tokenmakerwords(parsed)\n",
    "\n",
    "    # Ignore any documents with <50 words\n",
    "    if len(tokenised) < 100:\n",
    "        continue\n",
    "\n",
    "    # Sentence fragments\n",
    "    sentences = sent_tokenize(parsed)\n",
    "\n",
    "    # Build up dataframe\n",
    "    temp = pd.Series([filename, sentences])\n",
    "    d = d.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index(drop=True, inplace=True)\n",
    "d.columns = ['document', 'sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>allwords</th>\n",
       "      <th>mfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>031918comments2.authcheckdam.pdf</td>\n",
       "      <td>[ Section of Taxation Suite 400 1050 Connectic...</td>\n",
       "      <td>[[Section, of, Taxation, Suite, 400, 1050, Con...</td>\n",
       "      <td>[[(Section, NN), (of, IN), (Taxation, NNP), (S...</td>\n",
       "      <td>[section, taxation, suite, connecticut, avenue...</td>\n",
       "      <td>{'section': 25, 'taxation': 9, 'suite': 1, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>881961_CHECKLIST-2014_rev62714.pdf</td>\n",
       "      <td>[ CHECKLIST-2014_rev62714 ORDER CONFIRMATION C...</td>\n",
       "      <td>[[CHECKLIST-2014_rev62714, ORDER, CONFIRMATION...</td>\n",
       "      <td>[[(CHECKLIST-2014_rev62714, JJ), (ORDER, NNP),...</td>\n",
       "      <td>[order, confirmation, checklistorder, confirma...</td>\n",
       "      <td>{'order': 11, 'confirmation': 2, 'checklistord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DomesticWireFunds.pdf</td>\n",
       "      <td>[ ►►►►►PLEASE PRINT◄◄◄◄◄ WIRE TRANSFER PAYMENT...</td>\n",
       "      <td>[[►►►►►PLEASE, PRINT◄◄◄◄◄, WIRE, TRANSFER, PAY...</td>\n",
       "      <td>[[(►►►►►PLEASE, NN), (PRINT◄◄◄◄◄, NNP), (WIRE,...</td>\n",
       "      <td>[wire, transfer, payment, order, confirmation,...</td>\n",
       "      <td>{'wire': 1, 'transfer': 3, 'payment': 3, 'orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order Confirmation.pdf</td>\n",
       "      <td>[ Microsoft Word - Order Confirmation.doc Orde...</td>\n",
       "      <td>[[Microsoft, Word, -, Order, Confirmation.doc,...</td>\n",
       "      <td>[[(Microsoft, NNP), (Word, NNP), (-, :), (Orde...</td>\n",
       "      <td>[microsoft, word, order, order, confirmation, ...</td>\n",
       "      <td>{'microsoft': 1, 'word': 1, 'order': 6, 'confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient+Type+2+opt-out+letter+v1.0.pdf</td>\n",
       "      <td>[ (Title) (First name) (Surname) (Address line...</td>\n",
       "      <td>[[(, Title, ), (, First, name, ), (, Surname, ...</td>\n",
       "      <td>[[((, (), (Title, NN), (), )), ((, (), (First,...</td>\n",
       "      <td>[title, first, name, surname, address, line, a...</td>\n",
       "      <td>{'title': 2, 'first': 1, 'name': 1, 'surname':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r003.pdf</td>\n",
       "      <td>[ 1 Von: auto-confirm@amazon.co.uk Gesendet: S...</td>\n",
       "      <td>[[1, Von, :, auto-confirm, @, amazon.co.uk, Ge...</td>\n",
       "      <td>[[(1, CD), (Von, NNS), (:, :), (auto-confirm, ...</td>\n",
       "      <td>[von, gesendet, samstag, juli, betreff, order,...</td>\n",
       "      <td>{'von': 1, 'gesendet': 1, 'samstag': 1, 'juli'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sample Grade and Receipt Documents.pdf</td>\n",
       "      <td>[ Page 1 Sample Grade and Receipt Documents Ce...</td>\n",
       "      <td>[[Page, 1, Sample, Grade, and, Receipt, Docume...</td>\n",
       "      <td>[[(Page, NN), (1, CD), (Sample, NNP), (Grade, ...</td>\n",
       "      <td>[page, sample, grade, receipt, documents, cent...</td>\n",
       "      <td>{'page': 25, 'sample': 1, 'grade': 52, 'receip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>START_AM2014_QuickFireTwo.pdf</td>\n",
       "      <td>[ U.S. Attitudes toward Terrorism and Countert...</td>\n",
       "      <td>[[U.S., Attitudes, toward, Terrorism, and, Cou...</td>\n",
       "      <td>[[(U.S., NNP), (Attitudes, NNP), (toward, IN),...</td>\n",
       "      <td>[attitudes, toward, terrorism, counterterroris...</td>\n",
       "      <td>{'attitudes': 2, 'toward': 2, 'terrorism': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>START_ECDB_ViolencePerpetratedbySupportersofAQ...</td>\n",
       "      <td>[ National Consortium for the Study of Terrori...</td>\n",
       "      <td>[[National, Consortium, for, the, Study, of, T...</td>\n",
       "      <td>[[(National, NNP), (Consortium, NNP), (for, IN...</td>\n",
       "      <td>[national, consortium, study, terrorism, respo...</td>\n",
       "      <td>{'national': 26, 'consortium': 22, 'study': 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>START_ISIL_Lesson1_ObjectivesScenariosforISIL.pdf</td>\n",
       "      <td>[ Microsoft Word - U_SMA SOCCENT White Paper F...</td>\n",
       "      <td>[[Microsoft, Word, -, U_SMA, SOCCENT, White, P...</td>\n",
       "      <td>[[(Microsoft, NNP), (Word, NNP), (-, :), (U_SM...</td>\n",
       "      <td>[microsoft, word, soccent, white, paper, final...</td>\n",
       "      <td>{'microsoft': 1, 'word': 1, 'soccent': 1, 'whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>START_TranscendingOrganizationIndividualsandth...</td>\n",
       "      <td>[ START Analytical Brief © START, June 2014 1 ...</td>\n",
       "      <td>[[START, Analytical, Brief, ©, START, ,, June,...</td>\n",
       "      <td>[[(START, NNP), (Analytical, NNP), (Brief, NNP...</td>\n",
       "      <td>[start, analytical, brief, start, june, senior...</td>\n",
       "      <td>{'start': 16, 'analytical': 7, 'brief': 7, 'ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>water-companies-letter-SoS-to-Ofwat-180131.pdf</td>\n",
       "      <td>[ The Rt Hon Michael Gove MP From the Secretar...</td>\n",
       "      <td>[[The, Rt, Hon, Michael, Gove, MP, From, the, ...</td>\n",
       "      <td>[[(The, DT), (Rt, NNP), (Hon, NNP), (Michael, ...</td>\n",
       "      <td>[rt, hon, michael, gove, mp, secretary, state,...</td>\n",
       "      <td>{'rt': 1, 'hon': 1, 'michael': 2, 'gove': 2, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             document  \\\n",
       "0                    031918comments2.authcheckdam.pdf   \n",
       "1                  881961_CHECKLIST-2014_rev62714.pdf   \n",
       "2                               DomesticWireFunds.pdf   \n",
       "3                              Order Confirmation.pdf   \n",
       "4              Patient+Type+2+opt-out+letter+v1.0.pdf   \n",
       "5                                            r003.pdf   \n",
       "6              Sample Grade and Receipt Documents.pdf   \n",
       "7                       START_AM2014_QuickFireTwo.pdf   \n",
       "8   START_ECDB_ViolencePerpetratedbySupportersofAQ...   \n",
       "9   START_ISIL_Lesson1_ObjectivesScenariosforISIL.pdf   \n",
       "10  START_TranscendingOrganizationIndividualsandth...   \n",
       "11     water-companies-letter-SoS-to-Ofwat-180131.pdf   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   [ Section of Taxation Suite 400 1050 Connectic...   \n",
       "1   [ CHECKLIST-2014_rev62714 ORDER CONFIRMATION C...   \n",
       "2   [ ►►►►►PLEASE PRINT◄◄◄◄◄ WIRE TRANSFER PAYMENT...   \n",
       "3   [ Microsoft Word - Order Confirmation.doc Orde...   \n",
       "4   [ (Title) (First name) (Surname) (Address line...   \n",
       "5   [ 1 Von: auto-confirm@amazon.co.uk Gesendet: S...   \n",
       "6   [ Page 1 Sample Grade and Receipt Documents Ce...   \n",
       "7   [ U.S. Attitudes toward Terrorism and Countert...   \n",
       "8   [ National Consortium for the Study of Terrori...   \n",
       "9   [ Microsoft Word - U_SMA SOCCENT White Paper F...   \n",
       "10  [ START Analytical Brief © START, June 2014 1 ...   \n",
       "11  [ The Rt Hon Michael Gove MP From the Secretar...   \n",
       "\n",
       "                                                words  \\\n",
       "0   [[Section, of, Taxation, Suite, 400, 1050, Con...   \n",
       "1   [[CHECKLIST-2014_rev62714, ORDER, CONFIRMATION...   \n",
       "2   [[►►►►►PLEASE, PRINT◄◄◄◄◄, WIRE, TRANSFER, PAY...   \n",
       "3   [[Microsoft, Word, -, Order, Confirmation.doc,...   \n",
       "4   [[(, Title, ), (, First, name, ), (, Surname, ...   \n",
       "5   [[1, Von, :, auto-confirm, @, amazon.co.uk, Ge...   \n",
       "6   [[Page, 1, Sample, Grade, and, Receipt, Docume...   \n",
       "7   [[U.S., Attitudes, toward, Terrorism, and, Cou...   \n",
       "8   [[National, Consortium, for, the, Study, of, T...   \n",
       "9   [[Microsoft, Word, -, U_SMA, SOCCENT, White, P...   \n",
       "10  [[START, Analytical, Brief, ©, START, ,, June,...   \n",
       "11  [[The, Rt, Hon, Michael, Gove, MP, From, the, ...   \n",
       "\n",
       "                                                  pos  \\\n",
       "0   [[(Section, NN), (of, IN), (Taxation, NNP), (S...   \n",
       "1   [[(CHECKLIST-2014_rev62714, JJ), (ORDER, NNP),...   \n",
       "2   [[(►►►►►PLEASE, NN), (PRINT◄◄◄◄◄, NNP), (WIRE,...   \n",
       "3   [[(Microsoft, NNP), (Word, NNP), (-, :), (Orde...   \n",
       "4   [[((, (), (Title, NN), (), )), ((, (), (First,...   \n",
       "5   [[(1, CD), (Von, NNS), (:, :), (auto-confirm, ...   \n",
       "6   [[(Page, NN), (1, CD), (Sample, NNP), (Grade, ...   \n",
       "7   [[(U.S., NNP), (Attitudes, NNP), (toward, IN),...   \n",
       "8   [[(National, NNP), (Consortium, NNP), (for, IN...   \n",
       "9   [[(Microsoft, NNP), (Word, NNP), (-, :), (U_SM...   \n",
       "10  [[(START, NNP), (Analytical, NNP), (Brief, NNP...   \n",
       "11  [[(The, DT), (Rt, NNP), (Hon, NNP), (Michael, ...   \n",
       "\n",
       "                                             allwords  \\\n",
       "0   [section, taxation, suite, connecticut, avenue...   \n",
       "1   [order, confirmation, checklistorder, confirma...   \n",
       "2   [wire, transfer, payment, order, confirmation,...   \n",
       "3   [microsoft, word, order, order, confirmation, ...   \n",
       "4   [title, first, name, surname, address, line, a...   \n",
       "5   [von, gesendet, samstag, juli, betreff, order,...   \n",
       "6   [page, sample, grade, receipt, documents, cent...   \n",
       "7   [attitudes, toward, terrorism, counterterroris...   \n",
       "8   [national, consortium, study, terrorism, respo...   \n",
       "9   [microsoft, word, soccent, white, paper, final...   \n",
       "10  [start, analytical, brief, start, june, senior...   \n",
       "11  [rt, hon, michael, gove, mp, secretary, state,...   \n",
       "\n",
       "                                                mfreq  \n",
       "0   {'section': 25, 'taxation': 9, 'suite': 1, 'co...  \n",
       "1   {'order': 11, 'confirmation': 2, 'checklistord...  \n",
       "2   {'wire': 1, 'transfer': 3, 'payment': 3, 'orde...  \n",
       "3   {'microsoft': 1, 'word': 1, 'order': 6, 'confi...  \n",
       "4   {'title': 2, 'first': 1, 'name': 1, 'surname':...  \n",
       "5   {'von': 1, 'gesendet': 1, 'samstag': 1, 'juli'...  \n",
       "6   {'page': 25, 'sample': 1, 'grade': 52, 'receip...  \n",
       "7   {'attitudes': 2, 'toward': 2, 'terrorism': 20,...  \n",
       "8   {'national': 26, 'consortium': 22, 'study': 23...  \n",
       "9   {'microsoft': 1, 'word': 1, 'soccent': 1, 'whi...  \n",
       "10  {'start': 16, 'analytical': 7, 'brief': 7, 'ju...  \n",
       "11  {'rt': 1, 'hon': 1, 'michael': 2, 'gove': 2, '...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenize the sentences, cleanup, parts of speech tagging\n",
    "wordtokens(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 document  \\\n",
      "0        031918comments2.authcheckdam.pdf   \n",
      "1      881961_CHECKLIST-2014_rev62714.pdf   \n",
      "2                   DomesticWireFunds.pdf   \n",
      "3                  Order Confirmation.pdf   \n",
      "4  Patient+Type+2+opt-out+letter+v1.0.pdf   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  [ Section of Taxation Suite 400 1050 Connectic...   \n",
      "1  [ CHECKLIST-2014_rev62714 ORDER CONFIRMATION C...   \n",
      "2  [ ►►►►►PLEASE PRINT◄◄◄◄◄ WIRE TRANSFER PAYMENT...   \n",
      "3  [ Microsoft Word - Order Confirmation.doc Orde...   \n",
      "4  [ (Title) (First name) (Surname) (Address line...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [[Section, Taxation, Suite, Connecticut, Avenu...   \n",
      "1  [[ORDER, CONFIRMATION, CHECKLISTORDER, CONFIRM...   \n",
      "2  [[WIRE, TRANSFER, PAYMENT, ORDER, CONFIRMATION...   \n",
      "3  [[Microsoft, Word, Order, Order, Confirmation,...   \n",
      "4  [[Title, First, name, Surname, Address, line, ...   \n",
      "\n",
      "                                                 pos  \\\n",
      "0  [[(Section, NN), (Taxation, NNP), (Suite, NNP)...   \n",
      "1  [[(ORDER, NNP), (CONFIRMATION, NNP), (CHECKLIS...   \n",
      "2  [[(WIRE, NNP), (TRANSFER, NNP), (PAYMENT, NNP)...   \n",
      "3  [[(Microsoft, NNP), (Word, NNP), (Order, NNP),...   \n",
      "4  [[(Title, NNP), (First, NNP), (name, NN), (Sur...   \n",
      "\n",
      "                                            allwords  \\\n",
      "0  [section, taxation, suite, connecticut, avenue...   \n",
      "1  [order, confirmation, checklistorder, confirma...   \n",
      "2  [wire, transfer, payment, order, confirmation,...   \n",
      "3  [microsoft, word, order, order, confirmation, ...   \n",
      "4  [title, first, name, surname, address, line, a...   \n",
      "\n",
      "                                               mfreq  \n",
      "0  {'section': 25, 'taxation': 9, 'suite': 1, 'co...  \n",
      "1  {'order': 11, 'confirmation': 2, 'checklistord...  \n",
      "2  {'wire': 1, 'transfer': 3, 'payment': 3, 'orde...  \n",
      "3  {'microsoft': 1, 'word': 1, 'order': 6, 'confi...  \n",
      "4  {'title': 2, 'first': 1, 'name': 1, 'surname':...  \n"
     ]
    }
   ],
   "source": [
    "print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.aggregate of 0     [{'section': 1, 'taxation': 1, 'suite': 1, 'co...\n",
       "1     [{'order': 2, 'confirmation': 2, 'checklistord...\n",
       "2     [{'wire': 1, 'transfer': 2, 'payment': 3, 'ord...\n",
       "3     [{'microsoft': 1, 'word': 1, 'order': 2, 'conf...\n",
       "4     [{'title': 1, 'first': 1, 'name': 1, 'surname'...\n",
       "5     [{'von': 1, 'gesendet': 1, 'samstag': 1}, {'ju...\n",
       "6     [{'page': 2, 'sample': 1, 'grade': 11, 'receip...\n",
       "7     [{'attitudes': 2, 'toward': 2, 'terrorism': 5,...\n",
       "8     [{'national': 2, 'consortium': 2, 'study': 2, ...\n",
       "9     [{'microsoft': 1, 'word': 1, 'soccent': 1, 'wh...\n",
       "10    [{'start': 2, 'analytical': 2, 'brief': 2, 'ju...\n",
       "11    [{'rt': 1, 'hon': 1, 'michael': 1, 'gove': 1, ...\n",
       "Name: mfreq, dtype: object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['mfreq'].agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['isis', 'terrorism', 'bomb', 'consortium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isis ['START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014.pdf']\n",
      "terrorism ['START_AM2014_QuickFireTwo.pdf', 'START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014.pdf', 'START_ISIL_Lesson1_ObjectivesScenariosforISIL.pdf', 'START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014.pdf']\n",
      "bomb ['START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014.pdf']\n",
      "consortium ['START_AM2014_QuickFireTwo.pdf', 'START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014.pdf', 'START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014.pdf']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "word_matches = defaultdict(list)\n",
    "for word in keywords:\n",
    "    for idx, row in d.iterrows():\n",
    "        if word in row['allwords'] and not row['document'] in word_matches[word]:\n",
    "            word_matches[word].append(row['document'])\n",
    "\n",
    "for key, val in word_matches.items():\n",
    "    print(key, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
