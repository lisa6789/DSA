{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tika import parser\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk import FreqDist\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document tokenization after text pre-preprocessing to differentiate types then token based on type\n",
    "\n",
    "input_path = 'C:\\\\test'\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "d = pd.DataFrame(columns=['document', 'sentences', 'words', 'pos'])\n",
    "freq = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Tika to parse the file\n",
    "def parsewithtika(inputfile):\n",
    "    parsed = parser.from_file(inputfile)\n",
    "    # Extract the text content from the parsed file\n",
    "    psd = parsed[\"content\"]\n",
    "    # Convert double newlines into single newlines\n",
    "    psd.replace('\\n\\n', '\\n')\n",
    "    return psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenmakerwords(inputfile):\n",
    "    # Create tokens\n",
    "    tokens = word_tokenize(inputfile)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    import string\n",
    "    stripped = [w.strip(string.punctuation) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    text = nltk.Text(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language filter\n",
    "def filterlanguage(inputfile):\n",
    "    if detect(inputfile) != 'en':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokens, parts of speech tagging\n",
    "def wordtokens(dataframe):\n",
    "    dataframe['words'] = dataframe['sentences'].apply(word_tokenize)\n",
    "    dataframe['words'] = dataframe['words'].apply(lambda x: [item.lower() for item in x])\n",
    "    dataframe['words'] = dataframe['words'].apply(lambda x: [item.strip(string.punctuation) for item in x])\n",
    "    dataframe['words'] = dataframe['words'].apply(lambda x: [item for item in x if item.isalpha()])\n",
    "    dataframe['words'] = dataframe['words'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    dataframe['pos'] = dataframe['words'].apply(nltk.pos_tag)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031918comments2.authcheckdam.pdf\n",
      "0                     031918comments2.authcheckdam.pdf\n",
      "1    [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...\n",
      "dtype: object\n",
      "  document sentences words  pos  \\\n",
      "0      NaN       NaN   NaN  NaN   \n",
      "1      NaN       NaN   NaN  NaN   \n",
      "2      NaN       NaN   NaN  NaN   \n",
      "3      NaN       NaN   NaN  NaN   \n",
      "4      NaN       NaN   NaN  NaN   \n",
      "\n",
      "                                                   0    1  \n",
      "0                   031918comments2.authcheckdam.pdf  NaN  \n",
      "1  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "2                 881961_CHECKLIST-2014_rev62714.pdf  NaN  \n",
      "3  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "4                              DomesticWireFunds.pdf  NaN  \n",
      "881961_CHECKLIST-2014_rev62714.pdf\n",
      "0                   881961_CHECKLIST-2014_rev62714.pdf\n",
      "1    [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...\n",
      "dtype: object\n",
      "  document sentences words  pos  \\\n",
      "0      NaN       NaN   NaN  NaN   \n",
      "1      NaN       NaN   NaN  NaN   \n",
      "2      NaN       NaN   NaN  NaN   \n",
      "3      NaN       NaN   NaN  NaN   \n",
      "4      NaN       NaN   NaN  NaN   \n",
      "\n",
      "                                                   0    1  \n",
      "0                   031918comments2.authcheckdam.pdf  NaN  \n",
      "1  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "2                 881961_CHECKLIST-2014_rev62714.pdf  NaN  \n",
      "3  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "4                              DomesticWireFunds.pdf  NaN  \n",
      "DomesticWireFunds.pdf\n",
      "0                                DomesticWireFunds.pdf\n",
      "1    [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...\n",
      "dtype: object\n",
      "  document sentences words  pos  \\\n",
      "0      NaN       NaN   NaN  NaN   \n",
      "1      NaN       NaN   NaN  NaN   \n",
      "2      NaN       NaN   NaN  NaN   \n",
      "3      NaN       NaN   NaN  NaN   \n",
      "4      NaN       NaN   NaN  NaN   \n",
      "\n",
      "                                                   0    1  \n",
      "0                   031918comments2.authcheckdam.pdf  NaN  \n",
      "1  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "2                 881961_CHECKLIST-2014_rev62714.pdf  NaN  \n",
      "3  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "4                              DomesticWireFunds.pdf  NaN  \n",
      "Order Confirmation.pdf\n",
      "0                               Order Confirmation.pdf\n",
      "1    [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...\n",
      "dtype: object\n",
      "  document sentences words  pos  \\\n",
      "0      NaN       NaN   NaN  NaN   \n",
      "1      NaN       NaN   NaN  NaN   \n",
      "2      NaN       NaN   NaN  NaN   \n",
      "3      NaN       NaN   NaN  NaN   \n",
      "4      NaN       NaN   NaN  NaN   \n",
      "\n",
      "                                                   0    1  \n",
      "0                   031918comments2.authcheckdam.pdf  NaN  \n",
      "1  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "2                 881961_CHECKLIST-2014_rev62714.pdf  NaN  \n",
      "3  [\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...  NaN  \n",
      "4                              DomesticWireFunds.pdf  NaN  \n",
      "Orderconf.pdf\n"
     ]
    }
   ],
   "source": [
    "# Main loop function\n",
    "# Iterate over all files in the folder and process each one in turn\n",
    "for input_file in glob.glob(os.path.join(input_path, '*.*')):\n",
    "    # Grab the file name\n",
    "    filename = os.path.basename(input_file)\n",
    "    fname = os.path.splitext(filename)[0]\n",
    "    print(filename)\n",
    "\n",
    "    # Parse the file to get to the text\n",
    "    parsed = parsewithtika(input_file)\n",
    "\n",
    "    # Language detection algorithm is non - deterministic, which means that if you try to run it on a text which is\n",
    "    # either too short or too ambiguous, you might get different results every time you run it\n",
    "    if filterlanguage(parsed):\n",
    "        continue\n",
    "\n",
    "    tokenised = tokenmakerwords(parsed)\n",
    "    fdist = nltk.FreqDist(tokenised)\n",
    "    freq += fdist\n",
    "\n",
    "\n",
    "    # Ignore any documents with <50 words\n",
    "    if len(tokenised) < 100:\n",
    "        continue\n",
    "\n",
    "    # Sentence fragments\n",
    "    sentences = sent_tokenize(parsed)\n",
    "\n",
    "    # Build up dataframe\n",
    "    temp = pd.Series([filename,sentences])\n",
    "    print(temp)\n",
    "    d = d.append(temp,ignore_index=True)\n",
    "    print(d.head())\n",
    "#     pd.concat([d, pd.DataFrame([[filename, sentences]])])\n",
    "\n",
    "    # check for output folder and build if it doesn't exist\n",
    "    # if not os.path.exists(input_path + '\\\\output\\\\' + fname):\n",
    "    #     os.makedirs(input_path + '\\\\output\\\\' + fname)\n",
    "    # # write out the text extracted by tika\n",
    "    # f = open(input_path + '\\\\output\\\\' + '\\\\' + fname + '\\\\' + os.path.splitext(filename)[0] + '.txt', 'wb')\n",
    "    # f.write(parsed.encode('utf-8').strip())\n",
    "    # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document, sentences, words, pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01,-,Good,bank,statement.pdf\n",
      "01,-,Good,bank,statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-15 10:23:38,965 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031918comments2.authcheckdam.pdf\n",
      "031918comments2.authcheckdam\n",
      "881961_CHECKLIST-2014_rev62714.pdf\n",
      "881961_CHECKLIST-2014_rev62714\n",
      "bank-reconciliation-example.pdf\n",
      "bank-reconciliation-example\n",
      "Bishop_Book_4_eBook.pdf\n",
      "Bishop_Book_4_eBook\n",
      "britain_mag_media_pack.pdf\n",
      "britain_mag_media_pack\n",
      "c07Chemicalreactions_WEB.pdf\n",
      "c07Chemicalreactions_WEB\n",
      "cassandra_thedefinitiveguide.pdf\n",
      "cassandra_thedefinitiveguide\n",
      "children result( Individula and together ) v1 7-3-16.docx\n",
      "children result( Individula and together ) v1 7-3-16\n",
      "Correct bank statement.pdf\n",
      "Correct bank statement\n",
      "D3S_EN.pdf\n",
      "D3S_EN\n",
      "datascienceatthecommandline.pdf\n",
      "datascienceatthecommandline\n",
      "dis5790_parrainage_mmf_a5_4.pdf\n",
      "dis5790_parrainage_mmf_a5_4\n",
      "DomesticWireFunds.pdf\n",
      "DomesticWireFunds\n",
      "DTM_AprMay_2018.pdf\n",
      "DTM_AprMay_2018\n",
      "dubai 1 2.pdf\n",
      "dubai 1 2\n",
      "Early social interaction project for childen with autism   begining in the second year of life (1) 2.pdf\n",
      "Early social interaction project for childen with autism   begining in the second year of life (1) 2\n",
      "eng[1].htm\n",
      "eng[1]\n",
      "eula.1036.txt\n",
      "eula.1036\n",
      "Factors-Affecting-Rate-of-Reaction.pdf\n",
      "Factors-Affecting-Rate-of-Reaction\n",
      "Fireworks!-ConcertInPark08.pdf\n",
      "Fireworks!-ConcertInPark08\n",
      "HERO5Black_UM_ENG_REVC_Web.pdf\n",
      "HERO5Black_UM_ENG_REVC_Web\n",
      "iphone  en.pdf\n",
      "iphone  en\n",
      "Kaplan, Andreas - Users of the world, unite.pdf\n",
      "Kaplan, Andreas - Users of the world, unite\n",
      "Kuwait job.docx\n",
      "Kuwait job\n",
      "learningspark.pdf\n",
      "learningspark\n",
      "log.txt\n",
      "log\n",
      "manual_charge_2_en_US.pdf\n",
      "manual_charge_2_en_US\n",
      "Memes-and-the-evolution-of-religion-We-need-memetics-too.pdf\n",
      "Memes-and-the-evolution-of-religion-We-need-memetics-too\n",
      "Mohamed Salem  Religion, Spirituality and Psychiatry.pdf\n",
      "Mohamed Salem  Religion, Spirituality and Psychiatry\n",
      "MSAB_License_Management_Brazilian Portuguese.pdf\n",
      "MSAB_License_Management_Brazilian Portuguese\n",
      "MSAB_License_Management_Chinese.pdf\n",
      "MSAB_License_Management_Chinese\n",
      "MSAB_License_Management_English.pdf\n",
      "MSAB_License_Management_English\n",
      "MSAB_License_Management_French.pdf\n",
      "MSAB_License_Management_French\n",
      "MSAB_License_Management_German.pdf\n",
      "MSAB_License_Management_German\n",
      "MSAB_License_Management_Japanese.pdf\n",
      "MSAB_License_Management_Japanese\n",
      "MSAB_License_Management_Russian.pdf\n",
      "MSAB_License_Management_Russian\n",
      "MSAB_License_Management_Spanish.pdf\n",
      "MSAB_License_Management_Spanish\n",
      "MSAB_License_Management_Turkish.pdf\n",
      "MSAB_License_Management_Turkish\n",
      "nutritionals.pdf\n",
      "nutritionals\n",
      "oa_bitc_jargon_buster.pdf\n",
      "oa_bitc_jargon_buster\n",
      "Order Confirmation.pdf\n",
      "Order Confirmation\n",
      "Orderconf.pdf\n",
      "Orderconf\n",
      "P857_ImportantInformation-TermsAndConditions.pdf\n",
      "P857_ImportantInformation-TermsAndConditions\n",
      "Patient+Type+2+opt-out+letter+v1.0.pdf\n",
      "Patient+Type+2+opt-out+letter+v1.0\n",
      "Periodic-Table-Chemical-Reactions-Summary1.pdf\n",
      "Periodic-Table-Chemical-Reactions-Summary1\n",
      "Philosophy of Religion.pdf\n",
      "Philosophy of Religion\n",
      "pwd-coursework-II-scalability testing.pdf\n",
      "pwd-coursework-II-scalability testing\n",
      "r003.pdf\n",
      "r003\n",
      "README.txt\n",
      "README\n",
      "ReferenceCard.pdf\n",
      "ReferenceCard\n",
      "ReferenceCardForMac.pdf\n",
      "ReferenceCardForMac\n",
      "Religion-Security-Global-Uncertainties.pdf\n",
      "Religion-Security-Global-Uncertainties\n",
      "Results and comments.docx\n",
      "Results and comments\n",
      "Sample Bank Statement.pdf\n",
      "Sample Bank Statement\n",
      "Sample Grade and Receipt Documents.pdf\n",
      "Sample Grade and Receipt Documents\n",
      "sample-bank-statement.pdf\n",
      "sample-bank-statement\n",
      "south_cambs_magazine_summer_2018small.pdf\n",
      "south_cambs_magazine_summer_2018small\n",
      "sql-code-smells.pdf\n",
      "sql-code-smells\n",
      "STARTBackgroundReport_TerrorisminOlympicsSochiRussia_Jan2014.pdf\n",
      "STARTBackgroundReport_TerrorisminOlympicsSochiRussia_Jan2014\n",
      "STARTCongressionalTestimony_StateofAQandAffiliates_WilliamBraniff.pdf\n",
      "STARTCongressionalTestimony_StateofAQandAffiliates_WilliamBraniff\n",
      "STARTResearchBrief_Anatomizing.pdf\n",
      "STARTResearchBrief_Anatomizing\n",
      "STARTResearchBrief_CommunityPolicing_Feb2015.pdf\n",
      "STARTResearchBrief_CommunityPolicing_Feb2015\n",
      "STARTSymposium2015_CounterterrorismPanel.pdf\n",
      "STARTSymposium2015_CounterterrorismPanel\n",
      "STARTSymposium2015_IndividualRadicalizationPanel.pdf\n",
      "STARTSymposium2015_IndividualRadicalizationPanel\n",
      "START_AM2014_QuickFireTwo.pdf\n",
      "START_AM2014_QuickFireTwo\n",
      "START_CounteringInhumane_ResearchBrief_May2015.pdf\n",
      "START_CounteringInhumane_ResearchBrief_May2015\n",
      "START_CSTAB_ECDB_25YearsofIdeologicalHomicideVictimizationUS_March2016.pdf\n",
      "START_CSTAB_ECDB_25YearsofIdeologicalHomicideVictimizationUS_March2016\n",
      "START_CSTAB_JihadiIndustryAssessingOrganizationalLeadershipCyberProfiles_July2017.pdf\n",
      "START_CSTAB_JihadiIndustryAssessingOrganizationalLeadershipCyberProfiles_July2017\n",
      "START_CSTAB_ReactionsWaronTerrorism_Feb2017.pdf\n",
      "START_CSTAB_ReactionsWaronTerrorism_Feb2017\n",
      "START_CSTAB_USMuslimOpinionsAboutISISSyriaUSElection_June2017.pdf\n",
      "START_CSTAB_USMuslimOpinionsAboutISISSyriaUSElection_June2017\n",
      "START_DemystifyingGrayZoneConflict_Libya_Nov2016.pdf\n",
      "START_DemystifyingGrayZoneConflict_Libya_Nov2016\n",
      "START_DHS_SyriaBarometerSurvey_30June2016.pdf\n",
      "START_DHS_SyriaBarometerSurvey_30June2016\n",
      "START_ECDB_FinancialCrimesSchemesPerpetratedbyFarRightExtremists_June2015.pdf\n",
      "START_ECDB_FinancialCrimesSchemesPerpetratedbyFarRightExtremists_June2015\n",
      "START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014.pdf\n",
      "START_ECDB_ViolencePerpetratedbySupportersofAQAM_June2014\n",
      "START_Gruenewald_FarRightHomicideLoners.pdf\n",
      "START_Gruenewald_FarRightHomicideLoners\n",
      "START_GTD_OverviewofTerrorism2014_Aug2015.pdf\n",
      "START_GTD_OverviewofTerrorism2014_Aug2015\n",
      "START_ISIL_Lesson1_ObjectivesScenariosforISIL.pdf\n",
      "START_ISIL_Lesson1_ObjectivesScenariosforISIL\n",
      "START_ISIL_Lesson2_AnOrganizationalProfileoftheIslamicState.pdf\n",
      "START_ISIL_Lesson2_AnOrganizationalProfileoftheIslamicState\n",
      "START_ISIL_Part3_Script.pdf\n",
      "START_ISIL_Part3_Script\n",
      "START_IUSSD_GTDTerroristAttacksinUS_ResearchHighlight_Jan2014.pdf\n",
      "START_IUSSD_GTDTerroristAttacksinUS_ResearchHighlight_Jan2014\n",
      "START_JihadistTerroristPlotsUS_Dec2017.pdf\n",
      "START_JihadistTerroristPlotsUS_Dec2017\n",
      "START_LessonsLearnedfromMentalHealthAndEducation_EducatorSummary_Oct2015.pdf\n",
      "START_LessonsLearnedfromMentalHealthAndEducation_EducatorSummary_Oct2015\n",
      "START_McCauley_PsychologyofLoneActorTerrorists.pdf\n",
      "START_McCauley_PsychologyofLoneActorTerrorists\n",
      "START_PIRUS_ResearchBrief_Sept2017.pdf\n",
      "START_PIRUS_ResearchBrief_Sept2017\n",
      "START_ResearchBrief_HateCrimeTerror_May2016.pdf\n",
      "START_ResearchBrief_HateCrimeTerror_May2016\n",
      "START_Smith_GeospatialTemporalPatternsofLoneActorTerrorism.pdf\n",
      "START_Smith_GeospatialTemporalPatternsofLoneActorTerrorism\n",
      "START_TerrorismEnergyAttacks_ResearchBrief_June2015.pdf\n",
      "START_TerrorismEnergyAttacks_ResearchBrief_June2015\n",
      "START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014.pdf\n",
      "START_TranscendingOrganizationIndividualsandtheIslamicState_AnalyticalBrief_June2014\n",
      "START_UnderstandingLawEnforcementIntelligenceProcesses_July2014.pdf\n",
      "START_UnderstandingLawEnforcementIntelligenceProcesses_July2014\n",
      "START_UnderstandingLoneActorTerrorism_ResearchHighlight_Oct2013.pdf\n",
      "START_UnderstandingLoneActorTerrorism_ResearchHighlight_Oct2013\n",
      "START_Webber_EvaluatingJihadistNarratives.pdf\n",
      "START_Webber_EvaluatingJihadistNarratives\n",
      "tech & cultural appropriation 2012.pdf\n",
      "tech & cultural appropriation 2012\n",
      "ten-point-travel.pdf\n",
      "ten-point-travel\n",
      "Ticket_Prices_FulhamBroadway.pdf\n",
      "Ticket_Prices_FulhamBroadway\n",
      "tips_users_chemicals_workplace_en.pdf\n",
      "tips_users_chemicals_workplace_en\n",
      "travel-conditions-gotogate-uk-20150609.pdf\n",
      "travel-conditions-gotogate-uk-20150609\n",
      "UAE job.htm\n",
      "UAE job\n",
      "Using the Python Shell.pdf\n",
      "Using the Python Shell\n",
      "water-companies-letter-SoS-to-Ofwat-180131.pdf\n",
      "water-companies-letter-SoS-to-Ofwat-180131\n",
      "webcolors.txt\n",
      "webcolors\n",
      "                            document  \\\n",
      "0   031918comments2.authcheckdam.pdf   \n",
      "1   031918comments2.authcheckdam.pdf   \n",
      "2   031918comments2.authcheckdam.pdf   \n",
      "3   031918comments2.authcheckdam.pdf   \n",
      "4   031918comments2.authcheckdam.pdf   \n",
      "5   031918comments2.authcheckdam.pdf   \n",
      "6   031918comments2.authcheckdam.pdf   \n",
      "7   031918comments2.authcheckdam.pdf   \n",
      "8   031918comments2.authcheckdam.pdf   \n",
      "9   031918comments2.authcheckdam.pdf   \n",
      "10  031918comments2.authcheckdam.pdf   \n",
      "11  031918comments2.authcheckdam.pdf   \n",
      "12  031918comments2.authcheckdam.pdf   \n",
      "13  031918comments2.authcheckdam.pdf   \n",
      "14  031918comments2.authcheckdam.pdf   \n",
      "15  031918comments2.authcheckdam.pdf   \n",
      "16  031918comments2.authcheckdam.pdf   \n",
      "17  031918comments2.authcheckdam.pdf   \n",
      "18  031918comments2.authcheckdam.pdf   \n",
      "19  031918comments2.authcheckdam.pdf   \n",
      "20  031918comments2.authcheckdam.pdf   \n",
      "21  031918comments2.authcheckdam.pdf   \n",
      "22  031918comments2.authcheckdam.pdf   \n",
      "23  031918comments2.authcheckdam.pdf   \n",
      "24  031918comments2.authcheckdam.pdf   \n",
      "25  031918comments2.authcheckdam.pdf   \n",
      "26  031918comments2.authcheckdam.pdf   \n",
      "27  031918comments2.authcheckdam.pdf   \n",
      "28  031918comments2.authcheckdam.pdf   \n",
      "29  031918comments2.authcheckdam.pdf   \n",
      "..                               ...   \n",
      "70  031918comments2.authcheckdam.pdf   \n",
      "71  031918comments2.authcheckdam.pdf   \n",
      "72  031918comments2.authcheckdam.pdf   \n",
      "73  031918comments2.authcheckdam.pdf   \n",
      "74  031918comments2.authcheckdam.pdf   \n",
      "75  031918comments2.authcheckdam.pdf   \n",
      "76  031918comments2.authcheckdam.pdf   \n",
      "77  031918comments2.authcheckdam.pdf   \n",
      "78  031918comments2.authcheckdam.pdf   \n",
      "79  031918comments2.authcheckdam.pdf   \n",
      "80  031918comments2.authcheckdam.pdf   \n",
      "81  031918comments2.authcheckdam.pdf   \n",
      "82  031918comments2.authcheckdam.pdf   \n",
      "83  031918comments2.authcheckdam.pdf   \n",
      "84  031918comments2.authcheckdam.pdf   \n",
      "85  031918comments2.authcheckdam.pdf   \n",
      "86  031918comments2.authcheckdam.pdf   \n",
      "87  031918comments2.authcheckdam.pdf   \n",
      "88  031918comments2.authcheckdam.pdf   \n",
      "89  031918comments2.authcheckdam.pdf   \n",
      "90  031918comments2.authcheckdam.pdf   \n",
      "91  031918comments2.authcheckdam.pdf   \n",
      "92  031918comments2.authcheckdam.pdf   \n",
      "93  031918comments2.authcheckdam.pdf   \n",
      "94  031918comments2.authcheckdam.pdf   \n",
      "95  031918comments2.authcheckdam.pdf   \n",
      "96  031918comments2.authcheckdam.pdf   \n",
      "97  031918comments2.authcheckdam.pdf   \n",
      "98  031918comments2.authcheckdam.pdf   \n",
      "99  031918comments2.authcheckdam.pdf   \n",
      "\n",
      "                                            sentences  \\\n",
      "0   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...   \n",
      "1   These Comments \\nare submitted on behalf of th...   \n",
      "2   The Section of Taxation will be pleased to dis...   \n",
      "3   Sincerely, \\n\\n                           \\n  ...   \n",
      "4   William M. Paul, Acting Chief Counsel and Depu...   \n",
      "5   David Kautter, Assistant Secretary (Tax Policy...   \n",
      "6   Accordingly, they should not be construed as r...   \n",
      "7   Omri Marian, Vice Chair of the Section’s Teach...   \n",
      "8   Substantive contributions were made by Adam \\n...   \n",
      "9   The \\nComments were reviewed by Lisa Zarlenga,...   \n",
      "10  Although some of the members of the Section wh...   \n",
      "11  Contact: Omri Marian \\n  (949) 824-6493 \\n  om...   \n",
      "12  These developments raise important federal \\ni...   \n",
      "13  An important issue, and the focus of these Com...   \n",
      "14  A Hard Fork is a \\n“change to the software of ...   \n",
      "15                Hard Forks raise unique tax issues.   \n",
      "16  Specifically, does a holder of a \\ncryptocurre...   \n",
      "17                          If so, how much and when?   \n",
      "18  The significant volatility in the exchange pri...   \n",
      "19  As discussed further in these Comments, curren...   \n",
      "20  There are reasonable analogies to both taxable...   \n",
      "21  In light of the legal ambiguity, the significa...   \n",
      "22  We recommend that such guidance prescribe the ...   \n",
      "23  Taxpayers who owned a coin that was subject to...   \n",
      "24                                                 2.   \n",
      "25  The deemed value of the forked coin at the tim...   \n",
      "26               1 Notice 2014-21, 2014-16 I.R.B 938.   \n",
      "27  2 https://www.americanbar.org/content/dam/aba/...   \n",
      "28  3 These Comments also refer to virtual currenc...   \n",
      "29  27, 2017), \\n\\nhttps://blog.coinbase.com/what-...   \n",
      "..                                                ...   \n",
      "70  By analogy, a soft fork is \\nmore similar to t...   \n",
      "71  The new version typically recognizes documents...   \n",
      "72  There are many reasons for network participant...   \n",
      "73  For \\n\\nexample, one reason for Hard Forks is ...   \n",
      "74  For example, on August 1, 2017, Bitcoin split ...   \n",
      "75  Nonetheless, \\nboth BCH and BTC remain in exis...   \n",
      "76  In contrast, some forks are a response to user...   \n",
      "77  For example, in 2016, the Ethereum blockchain ...   \n",
      "78  In that case, the value of \\nthe original coin...   \n",
      "79  Even though original owners of \\nEthereum owne...   \n",
      "80  In the case of a Hard Fork, an owner of the or...   \n",
      "81  An owner that holds the original coin in a bas...   \n",
      "82  This requires some level of technological soph...   \n",
      "83  6 \\n \\n\\nand is inconvenient, but is not undul...   \n",
      "84  An owner that holds the original coin through ...   \n",
      "85  This is much easier \\nfor the average owner, b...   \n",
      "86  For example, a few days before the BCH Hard Fo...   \n",
      "87  Nonetheless, it is generally possible for an o...   \n",
      "88  In that manner, \\nthe owner generally should b...   \n",
      "89                                                II.   \n",
      "90  Potential Tax Treatments of Hard Forks  \\n\\n \\...   \n",
      "91  We believe \\nreasonable arguments may be made ...   \n",
      "92                                                 A.   \n",
      "93  Hard Fork as a Realization Event  \\n \\nThe Sup...   \n",
      "94  27, 2017), https://blog.coinbase.com/update-fo...   \n",
      "95  8 David Farmer, Update of Bitcoin Cash, THE CO...   \n",
      "96  9 Xapo Bitcoin Cash Update, https://support.xa...   \n",
      "97                       10 348 U.S. 426, 431 (1955).   \n",
      "98  7 \\n \\n\\nall gains except those specifically e...   \n",
      "99  One could argue that the ability to use the \\n...   \n",
      "\n",
      "                                                words  \\\n",
      "0   [section, taxation, suite, connecticut, avenue...   \n",
      "1   [comments, submitted, behalf, american, bar, a...   \n",
      "2   [section, taxation, pleased, discuss, comments...   \n",
      "3   [sincerely, karen, l, hawkins, chair, section,...   \n",
      "4   [william, paul, acting, chief, counsel, deputy...   \n",
      "5   [david, kautter, assistant, secretary, tax, po...   \n",
      "6   [accordingly, construed, representing, positio...   \n",
      "7   [omri, marian, vice, chair, section, teaching,...   \n",
      "8   [substantive, contributions, made, adam, chodo...   \n",
      "9   [comments, reviewed, lisa, zarlenga, chair, se...   \n",
      "10  [although, members, section, participated, pre...   \n",
      "11  [contact, omri, marian, omarian, kerry, ryan, ...   \n",
      "12  [developments, raise, important, federal, inco...   \n",
      "13  [important, issue, focus, comments, proper, fe...   \n",
      "14  [hard, fork, change, software, digital, curren...   \n",
      "15          [hard, forks, raise, unique, tax, issues]   \n",
      "16  [specifically, holder, cryptocurrency, experie...   \n",
      "17                                             [much]   \n",
      "18  [significant, volatility, exchange, prices, cr...   \n",
      "19  [discussed, comments, current, law, provides, ...   \n",
      "20  [reasonable, analogies, taxable, nontaxable, e...   \n",
      "21  [light, legal, ambiguity, significant, valuati...   \n",
      "22        [recommend, guidance, prescribe, following]   \n",
      "23  [taxpayers, owned, coin, subject, hard, fork, ...   \n",
      "24                                                 []   \n",
      "25  [deemed, value, forked, coin, time, realizatio...   \n",
      "26                                           [notice]   \n",
      "27                                            [https]   \n",
      "28  [comments, also, refer, virtual, currency, dig...   \n",
      "29                                            [https]   \n",
      "..                                                ...   \n",
      "70  [analogy, soft, fork, similar, release, new, v...   \n",
      "71  [new, version, typically, recognizes, document...   \n",
      "72  [many, reasons, network, participants, agree, ...   \n",
      "73  [example, one, reason, hard, forks, users, net...   \n",
      "74  [example, august, bitcoin, split, bitcoin, btc...   \n",
      "75  [nonetheless, bch, btc, remain, existence, enj...   \n",
      "76  [contrast, forks, response, user, mistrust, or...   \n",
      "77  [example, ethereum, blockchain, split, two, re...   \n",
      "78  [case, value, original, coin, classic, ethereu...   \n",
      "79  [even, though, original, owners, ethereum, own...   \n",
      "80  [case, hard, fork, owner, original, coin, must...   \n",
      "81  [owner, holds, original, coin, basic, wallet, ...   \n",
      "82  [requires, level, technological, sophisticatio...   \n",
      "83  [inconvenient, unduly, burdensome, reasonably,...   \n",
      "84  [owner, holds, original, coin, certain, types,...   \n",
      "85  [much, easier, average, owner, means, owners, ...   \n",
      "86  [example, days, bch, hard, fork, coinbase, sen...   \n",
      "87  [nonetheless, generally, possible, owner, tran...   \n",
      "88  [manner, owner, generally, able, go, processes...   \n",
      "89                                               [ii]   \n",
      "90  [potential, tax, treatments, hard, forks, hard...   \n",
      "91  [believe, reasonable, arguments, may, made, wa...   \n",
      "92                                                 []   \n",
      "93  [hard, fork, realization, event, supreme, cour...   \n",
      "94                                            [https]   \n",
      "95  [david, farmer, update, bitcoin, cash, coinbas...   \n",
      "96               [xapo, bitcoin, cash, update, https]   \n",
      "97                                                 []   \n",
      "98            [gains, except, specifically, exempted]   \n",
      "99  [one, could, argue, ability, use, forked, coin...   \n",
      "\n",
      "                                                  pos  \n",
      "0   [(section, NN), (taxation, NN), (suite, NN), (...  \n",
      "1   [(comments, NNS), (submitted, VBD), (behalf, J...  \n",
      "2   [(section, NN), (taxation, NN), (pleased, VBD)...  \n",
      "3   [(sincerely, RB), (karen, JJ), (l, NN), (hawki...  \n",
      "4   [(william, NN), (paul, NN), (acting, VBG), (ch...  \n",
      "5   [(david, NN), (kautter, NN), (assistant, NN), ...  \n",
      "6   [(accordingly, RB), (construed, VBN), (represe...  \n",
      "7   [(omri, JJ), (marian, JJ), (vice, NN), (chair,...  \n",
      "8   [(substantive, JJ), (contributions, NNS), (mad...  \n",
      "9   [(comments, NNS), (reviewed, VBD), (lisa, JJ),...  \n",
      "10  [(although, IN), (members, NNS), (section, NN)...  \n",
      "11  [(contact, NN), (omri, NN), (marian, JJ), (oma...  \n",
      "12  [(developments, NNS), (raise, VBP), (important...  \n",
      "13  [(important, JJ), (issue, NN), (focus, NN), (c...  \n",
      "14  [(hard, JJ), (fork, NN), (change, NN), (softwa...  \n",
      "15  [(hard, JJ), (forks, NNS), (raise, VB), (uniqu...  \n",
      "16  [(specifically, RB), (holder, NN), (cryptocurr...  \n",
      "17                                       [(much, JJ)]  \n",
      "18  [(significant, JJ), (volatility, NN), (exchang...  \n",
      "19  [(discussed, VBN), (comments, NNS), (current, ...  \n",
      "20  [(reasonable, JJ), (analogies, NNS), (taxable,...  \n",
      "21  [(light, JJ), (legal, JJ), (ambiguity, NN), (s...  \n",
      "22  [(recommend, NN), (guidance, NN), (prescribe, ...  \n",
      "23  [(taxpayers, NNS), (owned, VBD), (coin, NNS), ...  \n",
      "24                                                 []  \n",
      "25  [(deemed, VBN), (value, NN), (forked, VBN), (c...  \n",
      "26                                     [(notice, NN)]  \n",
      "27                                      [(https, NN)]  \n",
      "28  [(comments, NNS), (also, RB), (refer, VBP), (v...  \n",
      "29                                      [(https, NN)]  \n",
      "..                                                ...  \n",
      "70  [(analogy, NN), (soft, JJ), (fork, NN), (simil...  \n",
      "71  [(new, JJ), (version, NN), (typically, RB), (r...  \n",
      "72  [(many, JJ), (reasons, NNS), (network, NN), (p...  \n",
      "73  [(example, NN), (one, CD), (reason, NN), (hard...  \n",
      "74  [(example, NN), (august, NN), (bitcoin, NN), (...  \n",
      "75  [(nonetheless, RB), (bch, JJ), (btc, NN), (rem...  \n",
      "76  [(contrast, NN), (forks, NNS), (response, NN),...  \n",
      "77  [(example, NN), (ethereum, NN), (blockchain, V...  \n",
      "78  [(case, NN), (value, NN), (original, JJ), (coi...  \n",
      "79  [(even, RB), (though, IN), (original, JJ), (ow...  \n",
      "80  [(case, NN), (hard, JJ), (fork, NN), (owner, N...  \n",
      "81  [(owner, NN), (holds, VBZ), (original, JJ), (c...  \n",
      "82  [(requires, VBZ), (level, JJ), (technological,...  \n",
      "83  [(inconvenient, NN), (unduly, RB), (burdensome...  \n",
      "84  [(owner, NN), (holds, VBZ), (original, JJ), (c...  \n",
      "85  [(much, RB), (easier, JJR), (average, JJ), (ow...  \n",
      "86  [(example, NN), (days, NNS), (bch, RB), (hard,...  \n",
      "87  [(nonetheless, RB), (generally, RB), (possible...  \n",
      "88  [(manner, NN), (owner, NN), (generally, RB), (...  \n",
      "89                                         [(ii, NN)]  \n",
      "90  [(potential, JJ), (tax, NN), (treatments, NNS)...  \n",
      "91  [(believe, VB), (reasonable, JJ), (arguments, ...  \n",
      "92                                                 []  \n",
      "93  [(hard, JJ), (fork, NN), (realization, NN), (e...  \n",
      "94                                      [(https, NN)]  \n",
      "95  [(david, JJ), (farmer, NN), (update, JJ), (bit...  \n",
      "96  [(xapo, JJ), (bitcoin, NN), (cash, NN), (updat...  \n",
      "97                                                 []  \n",
      "98  [(gains, NNS), (except, IN), (specifically, RB...  \n",
      "99  [(one, CD), (could, MD), (argue, VB), (ability...  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Word tokenize the sentences, cleanup, parts of speech tagging\n",
    "wordtokens(doc)\n",
    "\n",
    "\n",
    "# TODO - clean up \\n lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.DataFrame(columns=['document', 'sentences', 'words', 'pos'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
